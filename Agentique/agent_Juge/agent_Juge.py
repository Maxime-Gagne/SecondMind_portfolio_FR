#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AgentJuge - Superviseur de Qualit√© et D√©tecteur d'Hallucinations
Module responsable de l'√©valuation normative des entr√©es (Retrieval) et des sorties (Generation).

Ce module impl√©mente une architecture de validation √† double d√©tente :
1.  **Juge A Priori (Retrieval Judge)** : √âvalue la pertinence des documents r√©cup√©r√©s par le RAG *avant* leur injection dans le contexte. Utilise des heuristiques lexicales (TF-IDF simplifi√©, correspondance de mots-cl√©s) pour filtrer le bruit.
2.  **Juge A Posteriori (Consistency Judge)** : √âvalue la facticit√© de la r√©ponse g√©n√©r√©e par le LLM *apr√®s* sa production. Utilise un mod√®le de langage sp√©cialis√© (MiniLLM/SLM) pour v√©rifier que chaque affirmation est √©tay√©e par le contexte (NLI - Natural Language Inference).

R√¥le Architectural :
    Agit comme un "Circuit Breaker". Si le score de coh√©rence chute sous un seuil critique,
    l'AgentJuge peut bloquer la r√©ponse ou forcer une reformulation, garantissant la fiabilit√© du syst√®me.
"""

import logging
import json
import yaml
import re
from typing import Dict, List, Any
from datetime import datetime
from collections import deque
from pathlib import Path
from agentique.base.META_agent import AgentBase
from agentique.base.contrats_interface import ResultatJuge
from agentique.sous_agents_gouvernes.agent_Parole.moteurs.moteur_mini_llm import (
    MoteurMiniLLM,
)  # <--- IMPORTANT


class AgentJuge(AgentBase):
    # 1. INJECTION DU MOTEUR MINI LLM
    def __init__(self, agent_recherche, moteur_mini_llm=None):
        super().__init__(nom_agent="AgentJuge")
        """
        Arbitre impartial de la cha√Æne de traitement cognitive.

        Cette classe centralise toutes les logiques d'√©valuation. Elle est con√ßue pour √™tre :
        - **Robuste** : G√®re les √©checs du moteur de jugement (fallback neutre).
        - **Agnostique** : Peut utiliser diff√©rents backends de v√©rification (Regex, LLM Local, API).
        - **M√©tacognitive** : Maintient des statistiques sur la qualit√© moyenne des r√©ponses pour d√©clencher des alertes de d√©rive.

        Attributes:
            agent_recherche (AgentRecherche): Source de v√©rit√© pour la v√©rification des faits.
            moteur_mini_llm (MoteurMiniLLM): Mod√®le l√©ger d√©di√© aux t√¢ches de classification binaire (Vrai/Faux) et de scoring.
        """

        self.agent_recherche = agent_recherche

        self.moteur_mini_llm = moteur_mini_llm
        if moteur_mini_llm:
            self.llm = moteur_mini_llm  # Utilise celui qu'on lui donne
        else:
            self.llm = (
                MoteurMiniLLM()
            )  # Sinon en charge un (Fallback) # <--- STOCKAGE DU MOTEUR

        # ... (Le reste de l'init est OK) ...
        config_root = self.auditor.get_path("config")
        self.config = self._load_config(config_root or "")

        # Acc√®s rapides aux sous-sections (source de v√©rit√© : YAML)
        self.cfg_limites = self.config
        self.cfg_decision = self.config.get("decision", {})
        self.cfg_pertinence = self.config.get("pertinence", {})

        # M√©moire interne
        self.historique_coherence = deque(maxlen=100)
        # Stats
        self.stats_manager.ajouter_stat_specifique("appels_pertinence_total", 0)
        self.stats_manager.ajouter_stat_specifique("appels_coherence_total", 0)
        self.stats_manager.ajouter_stat_specifique("coherence_moyenne", 1.0)
        self.stats_manager.ajouter_stat_specifique("echecs_coherence_total", 0)

        self.logger.info("‚úÖ AgentJuge initialis√©.")

    def _load_config(self, config_path: str) -> Dict:
        """Charge la configuration YAML de l'agent (source de v√©rit√© unique)."""
        if not config_path:
            self.logger.log_error(
                "‚ùå AgentJuge: chemin config introuvable (auditor.get_path('config') vide)."
            )
            return {}

        p = Path(config_path)

        # Le contrat des autres agents : 'config' pointe g√©n√©ralement vers un dossier.
        # On supporte aussi le cas o√π 'config_path' pointe d√©j√† vers un fichier.
        if p.is_dir():
            p = p / "config_juge.yaml"

        if not p.exists():
            self.logger.log_error(
                f"‚ùå AgentJuge: fichier de configuration introuvable: {p}"
            )
            return {}

        try:
            with open(p, "r", encoding="utf-8") as f:
                cfg_brute = yaml.safe_load(f) or {}
            return cfg_brute.get("configuration", {}) or {}
        except Exception as e:
            self.logger.log_error(
                f"Erreur lors du chargement de la configuration du Juge: {e}"
            )
            return {}

    # =================================================================
    # MISSION 1 : CALCUL DE PERTINENCE (AVANT G√âN√âRATION)
    # =================================================================

    def calculer_pertinence_semantique(
        self,
        prompt: str,
        souvenir_contenu: str,
        souvenir_titre: str,
        filtres_semantiques: List[Dict],
    ) -> float:
        """
        √âvalue la pertinence d'un document candidat pour le contexte (Juge A Priori).

        Impl√©mente un algorithme de scoring hybride optimis√© :
        1. **Lexical Match** : Calcule le taux de recouvrement des mots-cl√©s (apr√®s nettoyage et lemmatisation l√©g√®re).
        2. **Title Boost** : Applique un multiplicateur si les termes de la requ√™te apparaissent dans le titre du document.
        3. **Semantic Bonus** : Ajoute des points si le document correspond aux m√©tadonn√©es (Sujet/Action) attendues.

        Args:
            prompt (str): La requ√™te utilisateur.
            souvenir_contenu (str): Le texte du document candidat.

        Returns:
            float: Score de pertinence normalis√© [0.0 - 1.0].
        """
        # -> Met √† jour le compteur global de statistiques.
        self.stats_manager.incrementer_stat_specifique("appels_pertinence_total")
        # S√©curit√© types
        if not isinstance(souvenir_contenu, str):
            souvenir_contenu = str(souvenir_contenu) if souvenir_contenu else ""

        # --- 1. CONFIGURATION LINGUISTIQUE (Correctif Claude #2 et #3) ---
        # Liste noire : Mots grammaticaux fr√©quents (Stop Words) qui diluent le sens.
        # On pr√©f√®re une liste explicite plut√¥t qu'un filtre sur la longueur pour garder "IA", "UI", "DB"
        # Source de v√©rit√© : config_juge.yaml -> configuration.pertinence.stop_words
        stop_words_list = self.cfg_pertinence.get("stop_words")
        STOP_WORDS = set(stop_words_list or [])
        boost_titre = self.cfg_pertinence.get("boost_titre")
        bonus_sujet = self.cfg_pertinence.get("bonus_sujet")
        if boost_titre is None or bonus_sujet is None:
            raise RuntimeError(
                "‚ùå AgentJuge: configuration.pertinence incomplet (boost_titre/bonus_sujet)."
            )
        boost_titre = float(boost_titre)
        bonus_sujet = float(bonus_sujet)

        def extraire_mots(t):
            # 1. Nettoyage regex (alphanum√©rique)
            mots_bruts = re.findall(r"\w+", t.lower())
            mots_utiles = set()
            for m in mots_bruts:
                # 2. Filtrage Intelligent :
                # On garde les mots de 2 lettres (ex: IA, PC, DB) SAUF s'ils sont dans la Stop List
                if len(m) > 1 and m not in STOP_WORDS:
                    # 3. Lemmatisation "Pauvre" (Correctif Claude #1)
                    # On enl√®ve le 's' final pour matcher singulier/pluriel sans librairie lourde
                    # Ex: "scripts" -> "script"
                    root = m[:-1] if m.endswith("s") and len(m) > 3 else m
                    # "travaux" ‚Üí "travau" (pas id√©al, mais rare)
                    # "r√©seaux" ‚Üí "r√©seau" (utile)
                    if m.endswith("x") and len(m) > 4:
                        root = m[:-1]
                    mots_utiles.add(root)
            return mots_utiles

        # -> Extraction et nettoyage des mots du prompt
        prompt_mots = extraire_mots(prompt)

        if not prompt_mots:
            return 0.0

        # --- 2. ANALYSE CONTENU (Recall / Couverture) ---
        score_contenu = 0.0
        if souvenir_contenu:
            mots_contenu = extraire_mots(souvenir_contenu)
            if mots_contenu:
                inter_c = prompt_mots.intersection(mots_contenu)
                # Formule : Combien de mots du prompt sont pr√©sents dans le fichier ?
                score_contenu = len(inter_c) / len(prompt_mots)

        # --- 3. ANALYSE TITRE (Boost) ---
        score_titre = 0.0
        if souvenir_titre:
            titre_clean = souvenir_titre.replace("_", " ").replace(".", " ")
            mots_titre = extraire_mots(titre_clean)

            if mots_titre:
                inter_t = prompt_mots.intersection(mots_titre)
                if inter_t:
                    ratio_titre = len(inter_t) / len(prompt_mots)
                    # Boost titre (Plafonn√© √† 1.0) (pilot√© par la configuration)
                    # Un match sur le titre est un signal fort de pertinence
                    score_titre = min(1.0, ratio_titre * boost_titre)

        # --- 4. SCORE DE BASE (Strat√©gie Max) ---
        score_base = max(score_contenu, score_titre)

        # --- 5. BONUS S√âMANTIQUE RENFORC√â (Correctif Claude #4) ---
        bonus_semantique = 0.0
        texte_global = (souvenir_contenu + " " + souvenir_titre).lower()

        for filtre in filtres_semantiques:
            sujet = filtre.get("sujet", "").lower()
            # Bonus s√©mantique (valeur pilot√©e par la configuration)
            if sujet and sujet != "inconnu" and sujet in texte_global:
                bonus_semantique += bonus_sujet

        # --- 6. SCORE FINAL ---
        score_final = min(1.0, score_base + bonus_semantique)

        # Logging pour v√©rifier le d√©bouchage (Debug)
        if score_final > 0.4:
            self.logger.info(
                f"‚öñÔ∏è Pertinence OK: '{souvenir_titre[:25]}...' = {score_final:.2f}"
            )

        return round(score_final, 3)

    # =================================================================
    # MISSION 2 : CALCUL DE COH√âRENCE (APR√àS G√âN√âRATION)
    # =================================================================

    def evaluer_coherence_reponse(
        self, contexte_rag_str: str, prompt: str, reponse: str
    ) -> ResultatJuge:
        """
        V√©rifie l'ancrage factuel de la r√©ponse g√©n√©r√©e (Juge A Posteriori).

        Orchestre une t√¢che de "Fact-Checking" automatique via le MiniLLM :
        1. **Troncature Intelligente** : Adapte la taille du contexte pour respecter la fen√™tre d'attention du mod√®le juge.
        2. **Prompting Contradictoire** : Demande au mod√®le de d√©tecter activement les contradictions entre le Contexte et la R√©ponse.
        3. **Parsing Structur√©** : Extrait un verdict JSON formel (Score + Raison) de la sortie textuelle du mod√®le.

        G√®re les cas limites (Contexte vide, Mod√®le indisponible) par des strat√©gies de "Fail-Open" (Validation par d√©faut avec avertissement).

        Args:
            contexte_rag_str (str): Les faits bruts fournis au syst√®me.
            prompt (str): La question pos√©e.
            reponse (str): La r√©ponse √† v√©rifier.

        Returns:
            ResultatJuge: Objet contenant le verdict (Valide/Invalide), le score de confiance et la justification.
        """
        # -> Importation locale pour √©viter les cycles d'import, car on a besoin de la structure stricte de sortie.
        from agentique.base.contrats_interface import ResultatJuge

        # --- CONSTANTES DE S√âCURIT√â ---
        # Limite chars contexte (pilot√©e par la configuration).
        # Sur un contexte de 4k, √ßa laisse 2.5k pour le prompt syst√®me + la r√©ponse + la marge.
        # -> Plafond dur pour √©viter de faire planter le petit mod√®le local (MiniLLM).
        MAX_CHARS_CONTEXTE = int(self.cfg_limites.get("max_chars_contexte"))

        # --- 1. CLAUSE DE GARDE : CONTEXTE VIDE ---
        # -> V√©rifie si le contexte est vide, nul, ou contient moins de 10 caract√®res (inutile d'analyser du vide).
        if not contexte_rag_str or len(contexte_rag_str.strip()) < int(
            self.cfg_limites.get("min_chars_contexte")
        ):
            self.logger.info("‚öñÔ∏è Juge : Pas de contexte suffisant. Abstention.")
            # CORRECTION ICI
            # -> Cr√©ation d'un verdict "Neutre" (Valid√©=True, Score=0.5). On ne p√©nalise pas l'IA, on s'abstient juste.
            # -> Le champ 'details' est rempli pour expliquer l'abstention.
            res = ResultatJuge(
                valide=True,
                score=0.5,
                raison="Non √©valu√© (Contexte vide)",
                details={"mode": "abstention"},
            )
            # üõ°Ô∏èüëÅÔ∏è‚Äçüó®Ô∏èüõ°Ô∏è# VALIDATION FORMAT SORTIE
            # -> Appel √† l'Auditor pour v√©rifier que l'objet respecte le contrat (champs obligatoires pr√©sents).
            self.auditor.valider_format_sortie(res)
            return res

        # --- 2. PROTECTION CONTRE SURCHARGE ---
        taille_contexte = len(contexte_rag_str)
        # -> Si le texte d√©passe la limite d√©finie plus haut...
        if taille_contexte > MAX_CHARS_CONTEXTE:
            self.logger.log_warning(
                f"‚ö†Ô∏è Juge: Contexte trop gros ({taille_contexte} chars). Tronacature √† {MAX_CHARS_CONTEXTE}."
            )
            # -> TRONCATURE : On coupe le texte au plafond configur√© et on ajoute un marqueur visuel.
            # -> Cela permet de juger sur le d√©but du texte (souvent le plus pertinent) plut√¥t que de crasher.
            contexte_rag_str = (
                contexte_rag_str[:MAX_CHARS_CONTEXTE] + "\n... [CONTEXTE TRONQU√â] ..."
            )
            # Note: Si on voulait annuler ici, il faudrait aussi valider le ResultatJuge retourn√©.

        # ---------------------------------------

        # Si contexte pr√©sent (et nettoy√©), on lance l'√©valuation LLM standard
        try:
            # -> Construction du prompt final qui sera envoy√© au LLM (System Prompt + User Prompt).
            prompt_juge = self._construire_prompt_juge(
                contexte_rag_str, prompt, reponse
            )

            # -> V√©rification de s√©curit√© #1 : Est-ce que le moteur est branch√© ?
            if not self.moteur_mini_llm:
                # -> Si non, retour imm√©diat d'un score neutre (0.5) avec details vide {}.
                return ResultatJuge(
                    valide=True,
                    score=0.5,
                    raison="Juge indisponible (Pas de moteur)",
                    details={},
                )

            # -> V√©rification de s√©curit√© #2 : Taille TOTALE du prompt (Contexte + Question + R√©ponse).
            # -> M√™me si le contexte est coup√©, la r√©ponse de l'IA pourrait √™tre √©norme. On ajoute une marge configur√©e.
            if len(prompt_juge) > (
                MAX_CHARS_CONTEXTE + int(self.cfg_limites.get("marge_prompt_total"))
            ):  # Marge large
                self.logger.log_warning(
                    "‚ö†Ô∏è Juge: Prompt TOTAL trop gros. Abandon pour √©viter le crash."
                )
                # -> Abandon pour √©viter une erreur HTTP 400 (Bad Request) du serveur d'inf√©rence.
                return ResultatJuge(
                    valide=True,
                    score=0.5,
                    raison="Non √©valu√© (Trop volumineux)",
                    details={"mode": "securite_taille"},
                )

            # -> V√©rification de s√©curit√© #3 (Redondante mais plus s√©v√®re) : Si le moteur a disparu entre temps.
            if not self.moteur_mini_llm:
                # -> Ici on renvoie un score de 0.0 (Sanction technique) car c'est une anomalie inattendue √† ce stade.
                res = ResultatJuge(
                    valide=True,
                    score=0.0,
                    raison="Moteur Juge indisponible",
                    details={},
                )
                # üõ°Ô∏èüëÅÔ∏è‚Äçüó®Ô∏èüõ°Ô∏è# VALIDATION FORMAT SORTIE
                self.auditor.valider_format_sortie(res)
                return res

            # -> APPEL API : Envoi synchrone au LLM local.
            reponse_dict = self.moteur_mini_llm.generer(prompt_juge)

            # --- GESTION ERREUR MOTEUR (Le Fix 400 Bad Request) ---
            # -> Si le moteur renvoie None, ou un dictionnaire contenant "error", ou pas de cl√© "response".
            if (
                not reponse_dict
                or "error" in reponse_dict
                or not reponse_dict.get("response")
            ):
                self.logger.log_warning(
                    "‚ö†Ô∏è Juge: Le Moteur MiniLLM a √©chou√© (probablement Context Overflow). Abstention."
                )
                # -> Retour neutre (0.5) en incluant l'erreur brute dans les d√©tails pour le debug.
                return ResultatJuge(
                    valide=True,
                    score=0.5,
                    raison="Erreur technique Juge (Abstention)",
                    details={"error": str(reponse_dict)},
                )

            # -> Extraction du texte brut g√©n√©r√© par le LLM (cens√© √™tre du JSON).
            reponse_brute_juge = reponse_dict.get("response", "")

            # -> Parsing : Transformation du texte JSON en objet Python ResultatJuge.
            resultat = self._parser_reponse_juge(reponse_brute_juge)

            self.logger.info(
                f"‚öñÔ∏è Verdict Juge : {resultat.score}/5.0 ({resultat.raison[:50]}...)"
            )
            self._mettre_a_jour_coherence_moyenne(resultat.score)
            # -> On renvoie l'objet pars√© une seconde fois (Note: petite redondance ici, on pourrait retourner 'resultat').
            return self._parser_reponse_juge(reponse_brute_juge)

        except Exception as e:
            # -> CATCH-ALL : Si n'importe quoi d'autre plante (variable manquante, bug python).
            self.logger.log_error(f"Erreur critique Juge : {e}")
            # CORRECTION ICI
            # -> On renvoie un r√©sultat valide structurellement, mais neutre (0.5), avec l'exception dans les d√©tails.
            res = ResultatJuge(
                valide=True,
                score=0.5,
                raison=f"Erreur interne: {e}",
                details={"error": str(e)},
            )
            # üõ°Ô∏èüëÅÔ∏è‚Äçüó®Ô∏èüõ°Ô∏è# VALIDATION FORMAT SORTIE
            self.auditor.valider_format_sortie(res)
            return res

    def _construire_prompt_juge(
        self, contexte_rag_str: str, prompt: str, reponse: str
    ) -> str:
        """
        G√©n√®re le prompt syst√®me sp√©cialis√© pour le "Roleplay" du Juge.

        D√©finit les r√®gles d'√©valuation strictes pour le MiniLLM :
        - R√¥le : √âvaluateur impitoyable.
        - T√¢che : Comparaison Fait vs Affirmation.
        - Sortie : JSON strict uniquement.
        - √âchelle : 1.0 (Valid√©), 0.5 (Incertain), 0.0 (Hallucination).
        """
        return f"""
Tu es un √©valuateur de faits, strict et impitoyable. Ton but est de d√©tecter si la "R√©ponse G√©n√©r√©e" est factuellement support√©e par le "Contexte Fourni".

Tu dois r√©pondre **UNIQUEMENT** en format JSON.

1. Analyse la "R√©ponse G√©n√©r√©e" et extrais chaque affirmation factuelle.
2. Pour chaque affirmation, compare-la au "Contexte Fourni".
3. Donne un score de fiabilit√© STRICTEMENT entre 0.0 et 1.0 :
    * **1.0 (Parfait) :** Tous les faits sont valid√©s par le contexte.
    * **0.5 (Incertain) :** La r√©ponse est plausible mais contient des √©l√©ments non sourc√©s.
    * **0.0 (Hallucination) :** La r√©ponse contredit le contexte ou invente des faits.

---
**Contexte Fourni :**
{contexte_rag_str if contexte_rag_str else "Aucun contexte fourni."}

---
**Prompt Utilisateur :**
{prompt}

---
**R√©ponse G√©n√©r√©e (√† √©valuer) :**
{reponse}

---
**Ton √©valuation (FORMAT DE R√âPONSE JSON ATTENDU) :**
{{
    "raison": "Explication courte...",
    "score": 1.0
}}**
```json
"""

    def _extraire_bloc_json(self, texte: str) -> str:
        """
        Extracteur chirurgical de JSON dans une r√©ponse textuelle bruit√©e.

        Utilise un algorithme de comptage d'accolades (Bracket Counting) plut√¥t que des Regex
        pour isoler correctement les structures JSON imbriqu√©es, m√™me si le LLM bavarde avant ou apr√®s.
        Essentiel pour la fiabilit√© du pipeline automatis√©.
        """
        # -> Nettoyage basique des espaces autour du texte.
        texte = texte.strip()

        # -> Recherche de la premi√®re accolade ouvrante '{'.
        idx_debut = texte.find("{")
        # -> Si aucune accolade n'est trouv√©e, pas de JSON possible -> cha√Æne vide.
        if idx_debut == -1:
            return ""

        # -> Initialisation du compteur de profondeur (Pile logique).
        compteur = 0

        # -> On parcourt le texte caract√®re par caract√®re √† partir de la premi√®re accolade.
        for i, char in enumerate(texte[idx_debut:], start=idx_debut):
            # -> Si on ouvre un bloc, on incr√©mente la profondeur.
            if char == "{":
                compteur += 1
            # -> Si on ferme un bloc, on d√©cr√©mente.
            elif char == "}":
                compteur -= 1
                # -> Si le compteur retombe √† 0, c'est qu'on a ferm√© l'accolade principale initiale.
                # -> On a isol√© le bloc JSON complet, on le retourne imm√©diatement.
                if compteur == 0:
                    return texte[idx_debut : i + 1]

        # -> Si la boucle finit sans que le compteur soit retomb√© √† 0 (JSON mal ferm√©), on renvoie vide.
        return ""

    def _extraire_json_reponse(self, reponse_brute: str) -> Dict:
        """
        Convertisseur robuste Texte -> Dict avec m√©canismes d'auto-r√©paration.

        Tente de sauver les JSON mal form√©s (erreurs fr√©quentes des petits mod√®les) :
        - Suppression des balises Markdown parasites.
        - √âchappement des caract√®res sp√©ciaux probl√©matiques (Backslashes Windows).
        - Normalisation des sauts de ligne.

        Garantit que le pipeline ne crashe pas pour une virgule manquante.
        """
        import json
        import re

        # 1. Extraction par Pile (Fiable pour les objets imbriqu√©s)
        # -> On isole d'abord la partie qui ressemble √† du JSON pour √©viter de parser le texte autour.
        json_str = self._extraire_bloc_json(reponse_brute)

        # -> Si rien n'a √©t√© extrait, on renvoie un dict vide (Echec silencieux).
        if not json_str:
            return {}

        # -> Nettoyage des balises Markdown (```json et ```) souvent ajout√©es par les LLM.
        json_str = json_str.replace("```json", "").replace("```", "").strip()

        try:
            # -> Tentative 1 : Parsing standard. C'est le cas id√©al.
            return json.loads(json_str)
        except json.JSONDecodeError:
            # -> Si √©chec, on entre en mode "Chirurgie".
            try:
                # -> R√©paration Backslashes : Les chemins Windows (C:\User) cassent souvent le JSON.
                # -> Cette regex double les backslashes qui ne sont pas d√©j√† des √©chappements valides.
                json_str_fixed = re.sub(r'\\(?![/u"\\bfnrt])', r"\\\\", json_str)
                # -> Tentative 2 : Avec backslashes corrig√©s.
                return json.loads(json_str_fixed)
            except:
                # -> Si √©chec encore, tentative ultime.
                # -> R√©paration Newlines : Parfois les sauts de ligne dans les cha√Ænes cassent le format.
                # -> On remplace les sauts de ligne r√©els par des espaces.
                try:
                    return json.loads(json_str.replace("\n", " "))
                # -> Si tout √©choue, on abandonne et renvoie vide.
                except:
                    return {}

    def _parser_reponse_juge(self, reponse_brute: str) -> ResultatJuge:
        """
        Finalise la transformation de l'√©valuation brute en objet m√©tier valid√©.

        Effectue la normalisation finale des scores (Clamping 0.0-1.0), applique le seuil
        de d√©cision binaire (Valide/Invalide) d√©fini dans la configuration, et
        valide le tout via l'Auditor pour conformit√© contractuelle.
        """
        # -> Import local pour √©viter les cycles et garantir le typage.
        from agentique.base.contrats_interface import ResultatJuge

        # -> Appel de la m√©thode robuste d√©finie juste au-dessus pour avoir un Dict.
        data = self._extraire_json_reponse(reponse_brute)

        # -> Si le dict est vide (parsing √©chou√©), on renvoie un r√©sultat Neutre (0.5) mais Valide structurellement.
        # -> On inclut la r√©ponse brute dans 'details' pour comprendre pourquoi √ßa a rat√©.
        if not data:
            return ResultatJuge(
                valide=True,
                score=0.5,
                raison="Erreur technique JSON",
                details={"raw": reponse_brute},
            )

        # -> Lecture directe du score (plus besoin de diviser par 5 comme dans les anciennes versions).
        # -> .get(..., 0.0) prot√®ge contre l'absence de cl√©.
        score = float(data.get("score", 0.0))

        # -> S√©curit√© bornes : On s'assure (Clamping) que le score reste entre 0.0 et 1.0
        # -> Utile si le LLM hallucine un score hors bornes.
        score = max(0.0, min(1.0, score))

        # -> Instanciation de la Dataclass officielle.
        resultat = ResultatJuge(
            # -> Seuil de validation pilot√© par la configuration.
            valide=(score >= float(self.cfg_decision.get("seuil_validation"))),
            score=score,
            # -> R√©cup√©ration de la raison textuelle, ou valeur par d√©faut.
            raison=data.get("raison", "Analyse Juge"),
            # -> On stocke tout le dictionnaire brut dans les d√©tails pour tra√ßabilit√© compl√®te.
            details=data,
        )
        # üõ°Ô∏èüëÅÔ∏è‚Äçüó®Ô∏èüõ°Ô∏è# VALIDATION FORMAT SORTIE
        # -> L'Auditor v√©rifie que l'objet respecte bien le contrat (champs obligatoires, types).
        self.auditor.valider_format_sortie(resultat)

        # -> Retour de l'objet valid√© et typ√©.
        return resultat

    # ========================================
    # M√âTHODES UTILITAIRES DE STATISTIQUES
    # ========================================

    def _mettre_a_jour_coherence_moyenne(self, nouveau_score: float):
        ancienne = self.stats_manager.obtenir_stat_specifique("coherence_moyenne", 1.0)
        nouvelle = 0.1 * nouveau_score + 0.9 * ancienne
        self.stats_manager.definir_stat_specifique(
            "coherence_moyenne", round(nouvelle, 3)
        )
