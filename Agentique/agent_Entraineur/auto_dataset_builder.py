#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AutoDatasetBuilder - Pipeline d'Acquisition Automatique de Donn√©es (Data Engineering)
Module responsable de la transformation des interactions conversationnelles en datasets d'entra√Ænement pour le ML.

Ce module agit comme un filtre de qualit√© (Quality Gate) entre le flux de production (Runtime)
et le flux d'apprentissage (Training). Il garantit que seules les donn√©es pertinentes, propres
et significatives sont inject√©es dans la base d'entra√Ænement du classifieur d'intentions.

Strat√©gie "Data-Centric AI" :
    Plut√¥t que d'am√©liorer le mod√®le (SBERT), on am√©liore d'abord la donn√©e qui le nourrit.
    Le module applique des r√®gles heuristiques strictes pour √©liminer le bruit, les commandes syst√®me
    et les hallucinations potentielles.
"""

import json
import re
from pathlib import Path
from datetime import datetime
from agentique.base.META_agent import AgentBase
from agentique.base.contrats_interface import Interaction
from typing import Dict, Any, Optional
from agentique.base.META_agent import AgentBase
from agentique.base.contrats_interface import (
    ResultatIntention,
    CustomJSONEncoder,
)  # ‚úÖ AJOUT Encoder


class AutoDatasetBuilder(AgentBase):
    def __init__(self):
        super().__init__(nom_agent="AutoDatasetBuilder")
        """
        Ing√©nieur de donn√©es autonome.

        Cette classe g√®re l'append-only sur le fichier `batch_dataset.jsonl`. Elle est stateless
        mais applique une politique de filtrage configur√©e en dur (Blacklist, Min/Max length)
        pour prot√©ger le futur mod√®le contre la pollution des donn√©es.

        Attributes:
            dataset_path (Path): Chemin physique du fichier JSONL accumulant les connaissances.
            MIN_CHARS, MIN_WORDS (int): Seuils minimaux de richesse s√©mantique.
        """

        # Chemin du dataset (Source de v√©rit√© pour l'entra√Ænement)
        self.dataset_path = Path(
            r"D:\rag_personnel\data_training_center\Semi\intention_detector_SBERT\dataset\batch_dataset.jsonl"
        )
        self.dataset_path.parent.mkdir(parents=True, exist_ok=True)

        # --- CRIT√àRES DE QUALIT√â ---
        self.MIN_CHARS = 10  # Ex: "C'est quoi?" (11 chars) est limite mais ok
        self.MIN_WORDS = 3  # Ex: "Analyse ce fichier" (3 mots)
        self.MAX_CHARS = 2000  # Pour √©viter de noyer SBERT avec un livre entier

        # Commandes √† bannir (Bruit technique)
        self.BLACKLIST_STARTS = [
            "+1",
            "-1",
            "!!!",
            "recherche_web",
            "rechercher_memoire",
            "exit",
            "quit",
        ]

    def _nettoyer_texte(self, texte: str) -> str:
        """
        Normalisation textuelle pour l'entra√Ænement SBERT.

        SBERT performe mieux sur des phrases canoniques. Cette m√©thode :
        1. √âlimine les sauts de ligne excessifs et les tabulations (Flattening).
        2. R√©duit les espaces multiples √† un espace simple.
        3. Trim les espaces d√©but/fin.

        Args:
            texte (str): Le prompt brut de l'utilisateur.

        Returns:
            str: Le texte nettoy√© pr√™t pour le dataset.
        """
        if not texte:
            return ""
        # Remplace les sauts de ligne multiples et tabulations par un espace simple
        # (SBERT pr√©f√®re souvent une ligne continue ou des paragraphes propres)
        texte = re.sub(r"\s+", " ", texte).strip()
        return texte

    def _est_qualifie(self, prompt: str, intention: Any) -> bool:
        """
        Le "Quality Gate" (Porte de Qualit√©).

        D√©cide si une interaction m√©rite d'√™tre apprise par le syst√®me.
        Crit√®res de rejet :
        - **Bruit Technique** : Commandes syst√®me (+1, !!!, exit).
        - **Pauvret√© S√©mantique** : Prompts trop courts (< 10 chars ou < 3 mots).
        - **Incertitude** : Interactions class√©es comme "INCONNU" (on n'apprend pas l'ignorance).

        Args:
            prompt (str): Le texte nettoy√©.
            intention (Any): La classification propos√©e par le syst√®me.

        Returns:
            bool: True si la donn√©e est valide pour le Fine-Tuning.
        """
        if not prompt or not intention:
            return False

        # 1. Filtre Commandes Syst√®me
        for blocked in self.BLACKLIST_STARTS:
            if prompt.startswith(blocked):
                return False

        # 2. Filtre Longueur
        if len(prompt) < self.MIN_CHARS:
            return False

        if len(prompt.split()) < self.MIN_WORDS:
            return False

        # 3. Filtre Incertitude (Si l'IA a class√© comme INCONNU, on n'apprend pas cette b√™tise)
        # Note: On suppose que 'intention' est un objet ResultatIntention ou un dict
        try:
            # Gestion objet vs dict
            sujet = (
                intention.sujet.value
                if hasattr(intention, "sujet")
                else intention.get("sujet")
            )
            if sujet and "inconnu" in sujet.lower():
                return False
        except:
            pass  # Si on ne peut pas lire, dans le doute on garde si le texte est bon

        return True

    def ajouter_interaction(
        self, interaction: Interaction, source: str = "batch"
    ) -> bool:
        """
        Point d'entr√©e principal pour l'ingestion de donn√©es.

        Orchestre le pipeline complet :
        1. **Nettoyage** : Appel √† _nettoyer_texte.
        2. **Filtrage** : Appel √† _est_qualifie. Si rejet√©, logge l'info et arr√™te.
        3. **Troncature** : Coupe les textes trop longs (> 2000 chars) pour respecter la fen√™tre de contexte SBERT.
        4. **Extraction** : Cr√©e un objet `ResultatIntention` propre.
        5. **Persistance** : Ajoute la ligne JSONL au fichier dataset (Append-Only).

        Args:
            interaction (Interaction): L'objet source contenant prompt et intention.
            source (str): M√©tadonn√©e de provenance (ex: "batch", "manual_correction").

        Returns:
            bool: True si l'ajout a √©t√© effectu√© avec succ√®s.
        """
        try:
            # 1. Nettoyage
            prompt_clean = self._nettoyer_texte(interaction.prompt)

            # 2. Validation Qualit√© (Le Gatekeeper)
            if not self._est_qualifie(prompt_clean, interaction.intention):
                # ‚úÖ CORRECTION : Log de rejet ici, et retour False imm√©diat
                # On utilise INFO pour ne pas spammer les logs d'erreurs avec des rejets normaux
                self.logger.info(
                    f"üìâ Interaction rejet√©e (Filtre Qualit√©) : {prompt_clean[:50]}..."
                )
                return False

            # 3. Troncature intelligente
            if len(prompt_clean) > self.MAX_CHARS:
                prompt_clean = prompt_clean[: self.MAX_CHARS]

            # 4. Extraction des donn√©es
            nouvelle_donnee = ResultatIntention(
                prompt=prompt_clean,
                sujet=interaction.intention.sujet,
                action=interaction.intention.action,
                categorie=interaction.intention.categorie,
            )

            # 5. √âcriture Append (JSONL)
            with open(self.dataset_path, "a", encoding="utf-8") as f:
                # ‚úÖ AJOUT cls=CustomJSONEncoder pour transformer les Enums en strings
                json.dump(nouvelle_donnee, f, ensure_ascii=False, cls=CustomJSONEncoder)
                f.write("\n")

            self.logger.info(f"üìà Dataset enrichi (+1) : {prompt_clean[:30]}...")
            return True

        except Exception as e:
            self.logger.log_error(f"Erreur ajout dataset : {e}")
            return False
