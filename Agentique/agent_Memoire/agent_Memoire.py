#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AgentMemoire - Gestionnaire de Persistance et d'Ancrage Cognitif
Module responsable de l'Ã©criture, de la sauvegarde et de l'indexation de toutes les donnÃ©es du systÃ¨me.

Ce module implÃ©mente une stratÃ©gie de persistance en couches (Layered Persistence Strategy) :
1.  **Couche Brute (Safety Layer) :** Journalisation append-only (JSONL) pour garantir qu'aucune donnÃ©e n'est perdue en cas de crash.
2.  **Couche Transactionnelle (Short-Term) :** Fichiers JSON individuels reprÃ©sentant l'Ã©tat immÃ©diat de la conversation.
3.  **Couche SÃ©mantique (Long-Term) :** Vectorisation des interactions pour le RAG (Narratif) et des rÃ¨gles (LÃ©gislatif).
4.  **Couche IndexÃ©e (Search) :** Mise Ã  jour temps rÃ©el de l'index inversÃ© (Whoosh) pour la recherche par mots-clÃ©s.

Architecture "Twin-Engine" :
    L'agent gÃ¨re deux moteurs vectoriels distincts :
    - **Moteur Narratif :** Pour les souvenirs et l'historique (RAG classique).
    - **Moteur LÃ©gislatif :** Index dÃ©diÃ© exclusivement aux rÃ¨gles et lois, garantissant que la gouvernance ne se dilue pas dans la narration.
"""

import json
import os
from pathlib import Path
import yaml
from datetime import datetime
from dataclasses import asdict, is_dataclass
from typing import Dict, Any, List, Optional, Union, TYPE_CHECKING
from agentique.base.META_agent import AgentBase
from agentique.base.contrats_interface import (
    CustomJSONEncoder,
    Interaction,
    ArtefactCode,
    AnalyseContenu,
)
from agentique.sous_agents_gouvernes.agent_Memoire.moteur_vecteur import MoteurVectoriel

# âœ… AJOUT : Imports conditionnels pour l'Intellisense
if TYPE_CHECKING:
    from agentique.sous_agents_gouvernes.agent_Recherche.agent_Recherche import (
        AgentRecherche,
    )
    from agentique.sous_agents_gouvernes.agent_Memoire.moteur_vecteur import (
        MoteurVectoriel,
    )


class AgentMemoire(AgentBase):
    def __init__(
        self,
        agent_recherche: "AgentRecherche",  # âœ… Typage explicite
        moteur_vectoriel: Optional["MoteurVectoriel"] = None,  # âœ… Typage explicite
        root_dir: str = None,
        session_id: str = None,
    ):
        super().__init__(nom_agent="AgentMemoire")
        """
        ContrÃ´leur central des opÃ©rations d'Ã©criture (I/O Write).

        Contrairement Ã  l'AgentRecherche (Lecture), l'AgentMemoire est le seul autorisÃ© Ã  modifier
        l'Ã©tat permanent du systÃ¨me. Il assure la cohÃ©rence des donnÃ©es entre le disque physique,
        la base vectorielle (FAISS) et le moteur de recherche (Whoosh).

        Attributes:
            moteur_vectoriel (MoteurVectoriel): Base de donnÃ©es des souvenirs narratifs.
            moteur_regles (MoteurVectoriel): Base de donnÃ©es dÃ©diÃ©e aux rÃ¨gles de gouvernance.
            agent_recherche (AgentRecherche): DÃ©pendance injectÃ©e pour la mise Ã  jour des index de recherche.
        """

        # --- Chargement de la configuration ---
        config_path_str = self.auditor.get_path("config")
        if config_path_str and Path(config_path_str).exists():
            with open(config_path_str, "r", encoding="utf-8") as f:
                config_brute = yaml.safe_load(f)
            self.config = config_brute.get("configuration", {})
        else:
            self.config = {}

        # --- Initialisation des mÃ©moires actives (Lecture YAML) ---
        chemins_memoire_a_chercher = self.config.get("types_memoire_actives", [])
        if "reflexive" in chemins_memoire_a_chercher:
            chemins_memoire_a_chercher.remove("reflexive")
            chemins_memoire_a_chercher.insert(0, "reflexive")

        if agent_recherche is None:
            raise RuntimeError(
                "âŒ ERREUR CRITIQUE: agent_recherche est obligatoire pour AgentMemoire"
            )
        self.agent_recherche = agent_recherche

        # 1. MOTEUR NARRATIF (Souvenirs)
        self.moteur_vectoriel = moteur_vectoriel
        # 2. âœ… MOTEUR LÃ‰GISLATIF (RÃ¨gles - Nouveau Index DÃ‰DIÃ‰)
        # On calcule le chemin : memoire/regles/vecteurs
        path_regles = self.auditor.get_path("regles")
        if path_regles:
            path_index_regles = os.path.join(path_regles, "vecteurs")
            self.logger.info(
                f"âš–ï¸ Initialisation Moteur Vectoriel LÃ‰GISLATIF : {path_index_regles}"
            )
            self.moteur_regles = MoteurVectoriel(chemin_index=path_index_regles)
        else:
            self.logger.log_warning(
                "âš ï¸ Chemin 'regles' introuvable. Le moteur lÃ©gislatif est dÃ©sactivÃ©."
            )
            self.moteur_regles = None

    # ================================================================
    # 1. SAUVEGARDE BRUTE (BACKUP SÃ‰CURITÃ‰)
    # ================================================================
    def sauvegarder_interaction_brute(
        self,
        donnee_entree: Union[Interaction, str],  # Accepte Objet OU String (Role)
        contenu: str = None,
        session_id: str = None,
        message_turn: int = None,
        metadata: Dict = None,
    ) -> bool:
        """
        ExÃ©cute une journalisation de type "Write-Ahead Log" (WAL) pour la sÃ©curitÃ© des donnÃ©es.

        Cette mÃ©thode est critique : elle capture l'interaction brute avant tout traitement complexe.
        Elle utilise un mode "Append-Only" avec `os.fsync` pour garantir l'atomicitÃ© et la durabilitÃ©
        de l'Ã©criture, mÃªme en cas d'arrÃªt brutal du systÃ¨me.

        Polymorphisme :
            Accepte soit un objet `Interaction` structurÃ©, soit des donnÃ©es brutes (str),
            assurant la rÃ©trocompatibilitÃ© et la flexibilitÃ© des logs.

        Returns:
            bool: True si l'Ã©criture physique est confirmÃ©e.
        """
        try:
            # 1. RÃ©cupÃ©rer le dossier dâ€™Ã©criture
            dossier_path = self.auditor.get_path("brute")
            if not dossier_path:
                return False
            dossier = Path(dossier_path)
            if not dossier.exists():
                dossier.mkdir(parents=True, exist_ok=True)

            # 2. Nom du fichier journalier
            date_str = datetime.now().strftime("%Y-%m-%d")
            log_path = dossier / f"interactions_{date_str}.jsonl"

            # 3. PrÃ©parer les donnÃ©es Ã  sauvegarder
            data_to_save = {}

            # CAS A : On a reÃ§u un objet Interaction complet (Nouveau standard)
            if is_dataclass(donnee_entree):
                data_to_save = asdict(donnee_entree)
                # On ajoute un timestamp de log si pas prÃ©sent
                if "timestamp_log" not in data_to_save:
                    data_to_save["timestamp_log"] = datetime.now().isoformat()

            # CAS B : On a reÃ§u des arguments sÃ©parÃ©s (Ancien standard / Fallback)
            elif isinstance(donnee_entree, str) and contenu is not None:
                data_to_save = {
                    "timestamp": datetime.now(),
                    "role": donnee_entree,  # Ici donnee_entree est le role
                    "contenu": contenu,
                    "session_id": session_id,
                    "message_turn": message_turn,
                    "metadata": metadata or {},
                }
            else:
                self.logger.log_warning(f"Format brute inconnu: {type(donnee_entree)}")
                return False

            # 4. Ã‰criture Append (AtomicitÃ© via os.fsync)
            with open(log_path, "a", encoding="utf-8") as f:
                json_line = json.dumps(
                    data_to_save, ensure_ascii=False, cls=CustomJSONEncoder
                )
                f.write(json_line + "\n")
                f.flush()
                os.fsync(f.fileno())

            self.logger.log_thought(f"ğŸ”’ Backup brut sÃ©curisÃ© : {log_path.name}")
            return True

        except Exception as e:
            self.logger.log_error(f"âŒ Erreur sauvegarde brute: {e}")
            return False

    # ================================================================
    # 2. MÃ‰MORISATION ACTIVE (HISTORIQUE + RAG)
    # ================================================================
    def memoriser_interaction(self, interaction_element: Interaction) -> bool:
        """
        Orchestre le pipeline d'ingestion complet d'une interaction (Hot Path).

        Processus en 4 Ã©tapes synchrones :
        1. **Persistance Disque** : Ã‰criture d'un fichier JSON atomique dans 'historique/'.
        2. **Validation** : VÃ©rification stricte du schÃ©ma de donnÃ©es via Auditor.
        3. **Vectorisation** : Injection immÃ©diate dans le Moteur Narratif pour disponibilitÃ© RAG instantanÃ©e.
        4. **Indexation** : Mise Ã  jour de l'index Whoosh pour la recherche par mots-clÃ©s.

        Cette mÃ©thode transforme une "pensÃ©e vive" en "souvenir accessible".

        Args:
            interaction_element (Interaction): L'Ã©change complet (Prompt + RÃ©ponse + MÃ©tadonnÃ©es).

        Returns:
            bool: SuccÃ¨s global de la chaÃ®ne de mÃ©morisation.
        """
        try:
            # --- 1. PrÃ©paration du nom de fichier ---
            ts = interaction_element.meta.timestamp
            timestamp_clean = ts.replace(":", "").replace("-", "").replace(".", "")

            # Extraction sÃ©curisÃ©e des tags (via Intention)
            if interaction_element.intention:
                sujet_val = interaction_element.intention.sujet.value
                action_val = interaction_element.intention.action.value
                categorie_val = interaction_element.intention.categorie.value
            else:
                sujet_val = "inconnu"
                action_val = "inconnue"
                categorie_val = "inconnue"

            # Nettoyage
            s_clean = sujet_val.lower().replace(" ", "")
            a_clean = action_val.lower().replace(" ", "")
            c_clean = categorie_val.lower().replace(" ", "")

            nom_fichier = (
                f"interaction_{s_clean}_{a_clean}_{c_clean}_{timestamp_clean}.json"
            )

            chemin_historique = self.auditor.get_path("historique")
            if not chemin_historique:
                self.logger.log_error("Chemin 'historique' introuvable")
                return False

            chemin_fichier = Path(chemin_historique) / nom_fichier

            # ğŸ›¡ï¸ğŸ‘ï¸â€ğŸ—¨ï¸ğŸ›¡ï¸   # VALIDATION FORMAT SORTIE
            self.auditor.valider_format_sortie(interaction_element)

            # --- 2. Ã‰criture du Fichier JSON (La source pour le rÃ©sumÃ© diffÃ©rÃ©) ---
            try:
                with open(chemin_fichier, "w", encoding="utf-8") as f:
                    json.dump(
                        asdict(interaction_element),
                        f,
                        ensure_ascii=False,
                        indent=2,
                        cls=CustomJSONEncoder,
                    )
                    f.write("\n")
            except Exception as e:
                self.logger.log_error(f"Erreur Ã©criture fichier historique: {e}")
                return False

            self.logger.log_thought(f"ğŸ“œ Interaction mÃ©morisÃ©e (Tampon): {nom_fichier}")

            # --- 3. Vectorisation IMMÃ‰DIATE (Pour le court terme) ---
            # NOTE : On garde la vectorisation immÃ©diate de l'Ã©change brut pour que la mÃ©moire
            # court terme fonctionne tout de suite. Le rÃ©sumÃ© diffÃ©rÃ© viendra consolider plus tard.
            if self.moteur_vectoriel:
                try:
                    texte_concat = (
                        f"{interaction_element.prompt}\n{interaction_element.reponse}"
                    )
                    meta = {
                        "fichier": str(chemin_fichier),
                        "timestamp": interaction_element.meta.timestamp,
                        "session_id": interaction_element.meta.session_id,
                        "type": "historique_brut",  # DiffÃ©rent du "golden_path" futur
                    }
                    self.moteur_vectoriel.ajouter_fragment(texte_concat, meta)
                except Exception as e:
                    self.logger.log_warning(f"Echec vectorisation immÃ©diate: {e}")

            # --- 4. Indexation Whoosh ---
            if hasattr(self, "agent_recherche"):
                try:
                    self.agent_recherche.update_index(
                        contenu=f"{interaction_element.prompt} {interaction_element.reponse}",
                        type_memoire="historique",
                        sujet=sujet_val,
                        action=action_val,
                        categorie=categorie_val,
                        nouveau_fichier=str(chemin_fichier),
                    )
                except Exception as e:
                    self.logger.log_warning(f"Echec Whoosh: {e}")

            return True

        except Exception as e:
            self.logger.log_error(
                f"Erreur fatale memoriser_interaction: {e}", exc_info=True
            )
            return False

    def journaliser_trace_reflexive(
        self, trace_markdown: str, type_erreur: str, classification: str
    ):
        """
        Ancre les processus de mÃ©tacognition (RÃ©flexion sur soi) dans la mÃ©moire.

        Sauvegarde les rapports gÃ©nÃ©rÃ©s par l'AgentReflexor (Diagnostiques d'erreurs,
        auto-critiques) et les vectorise. Cela permet au systÃ¨me, dans le futur,
        de se "souvenir qu'il s'est dÃ©jÃ  trompÃ©" sur un sujet similaire (Learning form Failure).

        Args:
            trace_markdown (str): Le rapport d'analyse au format lisible.
            type_erreur (str): La catÃ©gorie de l'erreur (ex: "Hallucination", "Code").
        """
        # 1. Demander le *dossier* 'reflexive'
        chemin_dossier_reflexif = self.auditor.get_path("reflexive")

        if not chemin_dossier_reflexif:
            self.logger.log_error("âŒ Dossier 'reflexive' introuvable dans l'Auditor.")
            return

        chemin_fichier = Path(chemin_dossier_reflexif) / "journal_de_doute_reflexif.md"

        try:
            # 3. Ã‰crire dans le fichier .md (en mode 'append')
            with open(chemin_fichier, "a", encoding="utf-8") as f:
                f.write(trace_markdown + "\n")

            self.logger.info(
                f"âœ… Trace rÃ©flexive ({type_erreur}) ajoutÃ©e au journal .md."
            )

            # 4. AJOUTER AU MOTEUR VECTORIEL (SÃ‰MANTIQUE)
            # Vectorisation
            if self.moteur_vectoriel:
                meta = {
                    "type": "reflexive",
                    "origine": "boucle_reflexive",
                    "fichier": str(chemin_fichier),
                    "type_erreur": type_erreur,
                    "classification": classification,
                }
                self.moteur_vectoriel.ajouter_fragment(trace_markdown, meta)
                self.moteur_vectoriel._sauvegarder_index()
                self.logger.info("âœ… Trace rÃ©flexive vectorisÃ©e.")

            # Whoosh
            if hasattr(self, "agent_recherche"):
                self.agent_recherche.update_index(
                    contenu=trace_markdown,
                    type_memoire="reflexive",
                    sujet=classification,
                    action="reflexion",
                    categorie="gouvernance",
                )
            self.logger.info("âœ… Index Whoosh (reflexive) mis Ã  jour.")

        except Exception as e:
            self.logger.log_error(
                f"Erreur lors de la journalisation/indexation de la trace rÃ©flexive: {e}"
            )

    # ================================================================
    # MÃ‰THODES DE SAUVEGARDE DU CODE
    # ================================================================
    def sauvegarder_artefacts_code(self, artefacts: List[Dict]) -> bool:
        """
        Extrait, filtre et archive le capital code gÃ©nÃ©rÃ© par le LLM.

        RÃ´le double :
        1. **Extraction Physique** : Sauvegarde les snippets dans des fichiers rÃ©els (.py, .js)
           pour usage ultÃ©rieur ou audit.
        2. **Base de Connaissance Code (RAG)** : Alimente une base JSONL spÃ©cifique (`code_chunks.jsonl`)
           qui servira de contexte technique pour les futures tÃ¢ches de dÃ©veloppement.

        Filtre Intelligent :
           DÃ©tecte et ignore automatiquement les "Tool Calls" (JSON de commande) pour ne pas
           polluer la base de code avec des instructions systÃ¨me.

        Args:
            artefacts (List[Dict]): Liste des blocs de code extraits de la rÃ©ponse.
        """
        if not artefacts:
            return True

        # 1. Chargement mapping extensions depuis YAML
        cfg_art = self.config.get("artefacts_code", {})
        ext_map = cfg_art.get(
            "extensions_map",
            {
                "python": "py",
                "javascript": "js",
                "json": "json",
                "html": "html",
                "css": "css",
            },
        )
        ignore_tools = cfg_art.get("ignorer_tool_calls", True)

        try:
            # Chemins
            root_memoire = Path(self.auditor.get_path("memoire"))
            dir_extraits = root_memoire / "code" / "code_extraits"
            file_db_rag = root_memoire / "code" / "code_chunks.jsonl"

            dir_extraits.mkdir(parents=True, exist_ok=True)
            # Assurer que le dossier parent du fichier JSONL existe
            file_db_rag.parent.mkdir(parents=True, exist_ok=True)

            count_ok = 0

            for art in artefacts:
                # --- FILTRE : BYPASS TOOL CALLS ---
                # Si c'est du JSON et que Ã§a contient la signature d'un outil ("function": "...")
                # On ne sauvegarde PAS, car c'est une commande systÃ¨me, pas du code projet.
                if ignore_tools and art.get("langage", "").lower() == "json":
                    contenu_lower = art.get("contenu", "").lower()

                    # DÃ‰TECTION GÃ‰NÃ‰RIQUE : On cherche la clÃ© "function" suivie d'un nom
                    # On couvre les variantes d'espacement json : "function": ou "function" :
                    is_tool_call = ('"function":' in contenu_lower) or (
                        '"function" :' in contenu_lower
                    )

                    # On vÃ©rifie aussi la prÃ©sence d'"arguments" pour Ãªtre sÃ»r
                    has_arguments = ('"arguments":' in contenu_lower) or (
                        '"arguments" :' in contenu_lower
                    )

                    if is_tool_call and has_arguments:
                        self.logger.info(
                            f"ğŸš« Artefact ignorÃ© (Tool Call dÃ©tectÃ© : {art.get('id')})"
                        )
                        continue
                # ----------------------------------
                # 3. Utilisation de la map YAML
                lang = art.get("langage", "text").lower()
                ext = ext_map.get(lang, "txt")  # Utilise la map chargÃ©e dynamiquement

                ts_simple = datetime.now().strftime("%Y%m%d")
                filename = f"artifact_{ts_simple}_{art['id']}.{ext}"
                filepath = dir_extraits / filename

                if not filepath.exists():
                    try:
                        with open(filepath, "w", encoding="utf-8") as f:
                            f.write(art["contenu"])
                    except Exception:
                        pass

                # 2. PrÃ©paration EntrÃ©e RAG (CompatibilitÃ© ContexteCode)
                raw_analyse = art.get("analyse", art.get("metadata_analyse", {}))

                if is_dataclass(raw_analyse):
                    analyse_obj = raw_analyse
                else:
                    analyse_obj = AnalyseContenu(
                        mode=raw_analyse.get("mode", "AST"),
                        fonctions=raw_analyse.get("fonctions", []),
                        classes=raw_analyse.get("classes", []),
                        imports=raw_analyse.get("imports", []),
                        docstring=raw_analyse.get("docstring"),
                        erreurs=raw_analyse.get("erreurs"),
                        extras=raw_analyse.get("extras", {}),
                    )

                artefact_obj = ArtefactCode(
                    id=art.get("id", "unknown"),
                    hash=art.get("hash", "nohash"),
                    langage=art.get("langage", "python"),
                    contenu=art.get("contenu", ""),
                    timestamp=art.get("timestamp", datetime.now().isoformat()),
                    analyse=analyse_obj,
                    type="snippet_llm",
                )
                # ğŸ›¡ï¸ğŸ‘ï¸â€ğŸ—¨ï¸ğŸ›¡ï¸       # VALIDATION FORMAT SORTIE
                self.auditor.valider_format_sortie(artefact_obj)

                # 3. Append to JSONL
                with open(file_db_rag, "a", encoding="utf-8") as fdb:
                    json.dump(asdict(artefact_obj), fdb, ensure_ascii=False)
                    fdb.write("\n")

                count_ok += 1

            self.logger.log_thought(
                f"ğŸ’¾ Code archivÃ© : {count_ok} artefacts sauvegardÃ©s (ArtefactCode)."
            )
            return True

        except Exception as e:
            self.logger.log_error(
                f"âŒ Erreur sauvegarde artefacts code : {e}", exc_info=True
            )
            return False

    # ================================================================
    # 3. SAUVEGARDE GÃ‰NÃ‰RIQUE (Pour Reflexor etc.)
    # ================================================================
    def sauvegarder_memoire(
        self, contenu: Any, type_memoire: str, nom_fichier: str
    ) -> bool:
        """
        Interface d'Ã©criture gÃ©nÃ©rique pour les modules externes ou les injecteurs manuels.

        Permet de persister des donnÃ©es arbitraires (Feedback utilisateur, Configuration,
        DonnÃ©es brutes) dans l'arborescence mÃ©moire gÃ©rÃ©e, en dÃ©lÃ©guant la rÃ©solution
        des chemins sÃ©curisÃ©s Ã  l'Auditor.

        Args:
            contenu (Any): DonnÃ©e Ã  Ã©crire (Dict -> JSON, Str -> Texte).
            type_memoire (str): ClÃ© de dossier cible (ex: "reflexive", "persistante").
        """
        try:
            # 1. RÃ©solution du chemin de base via l'Auditor
            # type_memoire peut Ãªtre "reflexive", "persistante", "brute", etc.
            chemin_base = self.auditor.get_path(type_memoire)

            if not chemin_base:
                self.logger.log_error(
                    f"Type de mÃ©moire inconnu ou chemin introuvable : {type_memoire}"
                )
                return False

            # 2. Construction du chemin complet
            # On gÃ¨re le cas oÃ¹ nom_fichier contient dÃ©jÃ  un sous-dossier (ex: feedback/...)
            full_path = Path(chemin_base) / nom_fichier

            # Assurer que le dossier parent existe
            full_path.parent.mkdir(parents=True, exist_ok=True)

            # 3. Ã‰criture (JSON ou Texte)
            with open(full_path, "w", encoding="utf-8") as f:
                if isinstance(contenu, (dict, list)):
                    # Import local pour Ã©viter les dÃ©pendances circulaires
                    from agentique.base.contrats_interface import CustomJSONEncoder

                    json.dump(
                        contenu, f, cls=CustomJSONEncoder, ensure_ascii=False, indent=2
                    )
                else:
                    f.write(str(contenu))

            self.logger.info(
                f"ğŸ’¾ MÃ©moire sauvegardÃ©e ({type_memoire}) : {full_path.name}"
            )
            return True

        except Exception as e:
            self.logger.log_error(
                f"âŒ Erreur sauvegarde mÃ©moire gÃ©nÃ©rique : {e}", exc_info=True
            )
            return False

    # ================================================================
    # âœ… NOUVELLE MÃ‰THODE : VECTORISATION DÃ‰DIÃ‰E AUX RÃˆGLES
    # ================================================================
    def vectoriser_regle(self, contenu_regle: str, metadata: Dict) -> bool:
        """
        Injecte une nouvelle loi dans le "Moteur LÃ©gislatif" (Index Vectoriel DÃ©diÃ©).

        ImplÃ©mente une sÃ©paration architecturale critique : les rÃ¨gles de gouvernance
        ne sont pas mÃ©langÃ©es aux souvenirs narratifs. Cela garantit que lors d'une
        recherche de "Lois", le systÃ¨me ne rÃ©cupÃ¨re pas de "Discussions sur les lois",
        mais bien les directives elles-mÃªmes.

        Args:
            contenu_regle (str): Le texte impÃ©ratif de la rÃ¨gle.
            metadata (Dict): Contexte de crÃ©ation (ex: Trigger, Date, Origine).
        """
        if not self.moteur_regles:
            self.logger.log_error(
                "âŒ Moteur LÃ©gislatif non disponible. Impossible de vectoriser la rÃ¨gle."
            )
            return False

        try:
            # On force le type pour Ãªtre sÃ»r
            metadata["type"] = "regle_gouvernance"
            metadata["sub_type"] = "vector_store_dedie"

            self.moteur_regles.ajouter_fragment(texte=contenu_regle, meta=metadata)
            self.logger.info(
                f"âš–ï¸ RÃ¨gle vectorisÃ©e dans le moteur lÃ©gislatif (ID: {metadata.get('trigger', 'N/A')})"
            )
            return True
        except Exception as e:
            self.logger.log_error(f"Erreur vectorisation rÃ¨gle : {e}")
            return False

    # ================================================================
    # MÃ‰THODES UTILITAIRES
    # ================================================================

    def obtenir_statistiques(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'agent via le StatsManager."""
        # Note : Ne pas confondre avec obtenir_etat_memoire qui est plus dÃ©taillÃ©.
        return self.stats_manager.obtenir_statistiques()
