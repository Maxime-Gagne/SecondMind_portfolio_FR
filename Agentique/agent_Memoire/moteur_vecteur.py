#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MoteurVectoriel - C≈ìur de la M√©moire S√©mantique (Embeddings)
Module d'infrastructure g√©rant la base de donn√©es vectorielle locale du syst√®me.

Ce module encapsule la complexit√© math√©matique de la recherche s√©mantique :
1.  **Vectorisation (Encoding)** : Transformation du texte en vecteurs denses via `SentenceTransformer`.
2.  **Indexation (Indexing)** : Stockage optimis√© des vecteurs via `FAISS` (Facebook AI Similarity Search).
3.  **Persistance (Storage)** : Gestion synchronis√©e du fichier d'index binaire (.faiss) et des m√©tadonn√©es JSON.

R√¥le Architectural :
    Sert de backend de stockage pour :
    - La M√©moire Narrative (Souvenirs conversationnels).
    - La M√©moire L√©gislative (R√®gles et Lois).
    - La M√©moire R√©flexive (Traces d'erreurs pass√©es).
"""

import os
import yaml
import json
import numpy as np
import faiss
from datetime import datetime, timezone
from dataclasses import asdict, is_dataclass
from sentence_transformers import SentenceTransformer
from agentique.base.META_agent import AgentBase
from agentique.base.contrats_interface import CustomJSONEncoder


class MoteurVectoriel(AgentBase):
    """
    Wrapper haut niveau autour de la librairie FAISS et des mod√®les HuggingFace.

    Cette classe g√®re le cycle de vie complet des donn√©es vectorielles. Elle assure
    que chaque vecteur math√©matique (recherche) est strictement li√© √† ses m√©tadonn√©es
    textuelles (r√©sultat), garantissant l'int√©grit√© des donn√©es retourn√©es au RAG.

    Attributes:
        dim (int): Dimension de l'espace vectoriel (ex: 384 pour all-MiniLM-L6-v2).
        model (SentenceTransformer): Mod√®le d'embedding charg√© en m√©moire locale.
        index (faiss.Index): Structure de donn√©es optimis√©e pour la recherche de plus proches voisins (L2).
    """

    def __init__(self, chemin_index: str | None = None):
        super().__init__(nom_agent="MoteurVectoriel")

        # 1. Chargement Config (Source de V√©rit√©)
        self.config = self._load_config()
        self.vec_config = self.config.get("moteur_vectoriel", {})

        # 2. Param√®tres dynamiques
        self.dim = self.vec_config.get("dimension", 384)
        self.model_name = self.vec_config.get("model_name", "all-MiniLM-L6-v2")

        # 3. Chemin Index
        # Priorit√© : Argument > Config YAML > Auditor Default
        cfg_path_rel = self.vec_config.get("repertoire_index")
        auditor_path = self.auditor.get_path("vectorielle")

        if chemin_index:
            self.chemin_index = chemin_index
            if not os.path.exists(self.chemin_index):
                os.makedirs(self.chemin_index, exist_ok=True)
                self.logger.info(
                    f"üìÅ Cr√©ation du dossier vectoriel d√©di√© : {self.chemin_index}"
                )

        elif cfg_path_rel and self.auditor.get_path("memoire"):
            # Construction chemin absolu depuis racine m√©moire
            self.chemin_index = os.path.join(
                self.auditor.get_path("memoire"), "..", cfg_path_rel
            )
            self.chemin_index = os.path.abspath(self.chemin_index)
        else:
            self.chemin_index = auditor_path

        self.model = SentenceTransformer(self.model_name)

        self.fichier_index = os.path.join(self.chemin_index, "index.faiss")
        self.fichier_meta = os.path.join(self.chemin_index, "metadonnees.json")

        self.index = faiss.IndexFlatL2(self.dim)
        self.metadonnees: list[dict] = []

        self._charger_index()

    def _load_config(self):
        try:
            path = self.auditor.get_path("config", "memoire")
            if not path:
                # Fallback temporaire pour instanciation hors architecture compl√®te
                path = "config_memoire.yaml"

            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    return yaml.safe_load(f).get("configuration", {})
        except Exception:
            pass
        return {}

        # -------------------------------
        # Sauvegarde et chargement de l'IndexVectoriel
        # -------------------------------

    def _sauvegarder_index(self):
        """
        Assure la persistance atomique du "Dual-Store".

        Sauvegarde simultan√©ment :
        1. La structure binaire FAISS (`index.faiss`) contenant les vecteurs.
        2. Le fichier JSON (`metadonnees.json`) contenant le texte et les attributs.

        Cette synchronisation est critique : un d√©calage entre les deux fichiers corrompt la m√©moire.
        """
        try:
            chemin_faiss = os.path.join(self.chemin_index, "index.faiss")
            chemin_meta = os.path.join(self.chemin_index, "metadonnees.json")
            os.makedirs(self.chemin_index, exist_ok=True)

            faiss.write_index(self.index, chemin_faiss)
            with open(chemin_meta, "w", encoding="utf-8") as f:
                json.dump(
                    self.metadonnees,
                    f,
                    ensure_ascii=False,
                    indent=2,
                    cls=CustomJSONEncoder,
                )
        except Exception as e:
            print(f"[ERREUR SAUVEGARDE INDEX] {e}")

    def _charger_index(self):
        """Recharge l'index FAISS et les m√©tadonn√©es si disponibles."""
        try:
            chemin_faiss = os.path.join(self.chemin_index, "index.faiss")
            chemin_meta = os.path.join(self.chemin_index, "metadonnees.json")

            if os.path.exists(chemin_faiss) and os.path.exists(chemin_meta):
                self.index = faiss.read_index(chemin_faiss)
                with open(chemin_meta, "r", encoding="utf-8") as f:
                    self.metadonnees = json.load(f)
                print(
                    f"[INFO] Index vectoriel charg√© ({len(self.metadonnees)} entr√©es)."
                )
            else:
                print("[INFO] Aucun index existant, cr√©ation d'un nouveau.")
        except Exception as e:
            print(f"[ERREUR CHARGEMENT INDEX VECTORIEL] {e}")

    # -------------------------------
    # Ajout et recherche
    # -------------------------------
    def ajouter_fragment(self, texte: str, meta: dict | None = None) -> None:
        """
        Pipeline d'ingestion : Texte -> Vecteur -> Stockage.

        Processus :
        1. **Embedding** : Calcule le vecteur du texte via le mod√®le Transformer.
        2. **Indexation** : Ajoute le vecteur √† l'index FAISS.
        3. **Enrichissement** : Injecte le contenu textuel brut dans les m√©tadonn√©es (Critical Path)
           pour s'assurer que le r√©sultat de recherche contient la donn√©e lisible, pas juste un ID.
        4. **Commit** : D√©clenche une sauvegarde imm√©diate sur disque.

        Args:
            texte (str): Le contenu brut √† vectoriser.
            meta (dict, optional): M√©tadonn√©es contextuelles (Timestamp, Source, Type).
        """
        if not texte or not texte.strip():
            return

        # ‚úÖ Conversion Dataclass -> Dict si n√©cessaire
        if is_dataclass(meta):
            meta = asdict(meta)

        meta = dict(meta or {})
        meta.setdefault("timestamp", datetime.now(timezone.utc).isoformat())

        # CORRECTION CRITIQUE : Sauvegarde du contenu textuel
        # Sans cela, la recherche renvoie un emplacement vide.
        if "contenu" not in meta:
            meta["contenu"] = texte

        v = self.model.encode([texte])[0].astype(np.float32)
        self.index.add(np.array([v]))

        meta.setdefault("len", len(texte))
        self.metadonnees.append(meta)
        self._sauvegarder_index()

    def rechercher(self, requete: str, top_k: int = 5) -> list[dict]:
        """
        Ex√©cute une recherche par similarit√© s√©mantique (Semantic Search).

        Processus :
        1. Vectorise la requ√™te utilisateur (Query Embedding).
        2. Interroge FAISS pour trouver les `top_k` plus proches voisins (Distance L2).
        3. Convertit la distance euclidienne en score de similarit√© normalis√© (0 √† 1).
        4. Reconstruit les objets r√©sultats en fusionnant score et m√©tadonn√©es.

        Args:
            requete (str): La phrase ou le concept √† rechercher.
            top_k (int): Nombre de r√©sultats maximum √† retourner.

        Returns:
            list[dict]: Liste de r√©sultats format√©s [{"score": float, "meta": dict}].
        """
        if self.index.ntotal == 0:
            return []
        vq = self.model.encode([requete])[0].astype(np.float32)
        D, I = self.index.search(np.array([vq]), top_k)
        out = []
        for idx, dist in zip(I[0], D[0]):
            if 0 <= idx < len(self.metadonnees):
                out.append(
                    {"score": 1.0 / (1.0 + float(dist)), "meta": self.metadonnees[idx]}
                )
        return out
